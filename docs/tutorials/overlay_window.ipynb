{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use VTKOverlayWindow\n",
    "scikit-surgeryvtk provides a simple PySide2/VTK widget called VTKOverlayWindow for doing simple augmented reality (AR) overlays, using calibrated parameters, like those obtained from OpenCV. The video image is rendered as a background layer, with VTK models as a foreground layer. This is not very photo-realistic, but most researchers are focussing on registration/alignment rather than true 3D perception.\n",
    "\n",
    "In this page, we give a brief overview of the VTKOverlayWindow, a more detailed tutorial can be found in [SciKit-Surgery Augmented Reality Tutorial](https://scikit-surgerytutorial01.readthedocs.io/en/latest/)\n",
    "\n",
    "The Jupyter notebook for this page can be found in the `docs/tutorials` folder of the [code repository](https://github.com/UCL/scikit-surgeryvtk/).\n",
    "\n",
    "## Required modules\n",
    "This tutorial requires numpy, scikit-surgeryvtk, scikit-surgeryutils and opencv-contrib-python.\n",
    "\n",
    "## Quick implementation\n",
    "One of the most common uses is to overlay some models on a camera feed, and a sample implementation is included in the scikit-surgeryutils module, which requires only a few lines of code.\n",
    "\n",
    "**Note** - Running Qt Widgets from a Jupyter notebook can be a bit temperemental. Remember to close any Qt windows once you have finished with them, before moving onto a different section. If there are any issues, restarting the Jupyter kernel should be sufficient to fix.\n",
    "\n",
    "The code can also be run as a standard .py script file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sksurgeryutils.common_overlay_apps as coa\n",
    "from PySide2 import QtWidgets, QtCore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will launch a Qt widget in a new window, where you should be able to interact with the loaded models (drag/rotate etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Code\\Python\\scikit-surgery\\scikit-surgeryvtk\\docs\\tutorials\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QtCore.QCoreApplication.instance()\n",
    "if app is None:\n",
    "    app = QtWidgets.QApplication([])\n",
    "\n",
    "camera_source = 0\n",
    "wind = coa.OverlayOnVideoFeed(camera_source)\n",
    "wind.add_vtk_models_from_dir('../../tests/data/models/Liver')\n",
    "wind.start()\n",
    "\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Implementation\n",
    "The `OverlayOnVideoFeed` class has an `update` method which is called to read a new frame from the webcam and display it in the widget. By writing our own `update` method, we can add additional functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PySide2 import QtWidgets, QtCore\n",
    "import sksurgeryvtk.widgets.vtk_overlay_window as OW\n",
    "import sksurgeryvtk.models.vtk_surface_model as SM\n",
    "import sksurgeryvtk.models.vtk_surface_model_directory_loader as SMDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a new class, using a `QTimer` to call the `update` method, to which we can add whatever processing is desired. In this instance it just flips the video once it has been received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverlayApp():\n",
    "    \n",
    "    def __init__(self, video_source):\n",
    "        self.vtk_overlay_window = OW.VTKOverlayWindow()\n",
    "        self.video_source = cv2.VideoCapture(video_source)\n",
    "        \n",
    "        self.timer = QtCore.QTimer()\n",
    "        self.timer.timeout.connect(self.update)\n",
    "\n",
    "        update_frequency_ms = 100\n",
    "        self.timer.start(update_frequency_ms)\n",
    "        \n",
    "        self.vtk_overlay_window.show()\n",
    "        \n",
    "    def update(self):\n",
    "        ret, img = self.video_source.read()\n",
    "        img = cv2.flip(img, 0)\n",
    "        self.vtk_overlay_window.set_video_image(img)\n",
    "        self.vtk_overlay_window._RenderWindow.Render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = QtCore.QCoreApplication.instance()\n",
    "if app is None:\n",
    "    app = QtWidgets.QApplication([])\n",
    "\n",
    "camera_source = 0\n",
    "overlay_app = OverlayApp(camera_source)\n",
    "\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay models can be loaded from a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = QtCore.QCoreApplication.instance()\n",
    "if app is None:\n",
    "    app = QtWidgets.QApplication([])\n",
    "\n",
    "camera_source = 0\n",
    "overlay_app = OverlayApp(camera_source)\n",
    "\n",
    "model_dir = '../../tests/data/models/Liver'\n",
    "model_loader = SMDL.VTKSurfaceModelDirectoryLoader(model_dir)\n",
    "\n",
    "overlay_app.vtk_overlay_window.add_vtk_models(model_loader.models)\n",
    "\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or from individual files. It is also possible to set the colour and opacity individually for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QtCore.QCoreApplication.instance()\n",
    "if app is None:\n",
    "    app = QtWidgets.QApplication([])\n",
    "\n",
    "camera_source = 0\n",
    "overlay_app = OverlayApp(camera_source)\n",
    "\n",
    "liver_file= '../../tests/data/models/Liver/liver.vtk'\n",
    "portal_vein_file = '../../tests/data/models/Liver/portal_vein.vtk'\n",
    "\n",
    "liver_model = SM.VTKSurfaceModel(liver_file, colour = [1.0, 0.0, 0.0], opacity = 0.5)\n",
    "vein_model = SM.VTKSurfaceModel(portal_vein_file, colour = [0.0, 1.0, 0.0])\n",
    "\n",
    "\n",
    "overlay_app.vtk_overlay_window.add_vtk_models([liver_model, vein_model])\n",
    "\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Camera Parameters\n",
    "\n",
    "If you want to use a calibrated camera, it is assumed that the rendering is to be done in undistorted space. So, you would provide an undistorted image to the `set_video_image` method. This means that to get a correct AR overlay, you simply need to set the camera intrinsic parameters, and the camera extrinsics (pose, position and orientation).\n",
    "\n",
    "The extrinsics are defined as being the camera to world matrix, i.e. to place the camera at the correct position in the world. If you are trying to set the pose to verify an OpenCV camera calibration, and are using the OpenCV extrinsic matrix from the calibration process, then this is in effect a transformation from model (chessboard) to camera, so youâ€™d need to invert the OpenCV extrinsic matrix.\n",
    "\n",
    "Once you have appropriate parameters, you can pass them to the overlay window:\n",
    "\n",
    "```python\n",
    "vtk_overlay_window = VTKOverlayWindow()\n",
    "intrinsics = # get intrinsics somehow, 3x3 numpy array\n",
    "vtk_overlay_window.set_camera_matrix(intrinsics) \n",
    "vtk_overlay_window.show()\n",
    "\n",
    "while(True):\n",
    "\n",
    "  undistorted_rgb_image = # get undistorted RGB image somehow.\n",
    "  vtk_overlay_window.set_video_image(undistorted_rgb_image)\n",
    "\n",
    "  camera_to_world = # compute camera to world transform\n",
    "  vtk_overlay_window.set_camera_pose(camera_to_world)\n",
    " ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
